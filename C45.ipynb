{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTELIGENCIA ARTIFICIAL - EVALUACIÓN 1\n",
    "Integrantes: Sebastian Racedo y Sebastian Valle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importaremos las librerias que necesitarems para llevar a cabo la implementación de nuestro algoritmo.\n",
    " - Usaremos la libreria math para operaciones matematicas al momento de calcular la entropia\n",
    " - Usaremos la libreria pandas para poder manejar los datasets de una manera optima\n",
    " - Usaremos la libreria numpy para las operaciones con matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar clase Node y como sera el proceso de creación de nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, entropy_value, attribute_name, attribute_value, is_final_decision, parent, decision_value=\"-\"):\n",
    "        self.children = []\n",
    "        self.entropy_value = entropy_value\n",
    "        self.decision_value = decision_value\n",
    "        self.attribute_name = attribute_name\n",
    "        self.attribute_value = attribute_value\n",
    "        self.parent = parent\n",
    "        self.is_final_decision = is_final_decision\n",
    "        \n",
    "    def addChild(self, node):\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def getDecisionValues(self):\n",
    "        if self.is_final_decision:\n",
    "            return [self.decision_value]\n",
    "        \n",
    "        values = set()\n",
    "        for child in self.children:\n",
    "            child_values = child.getDecisionValues()\n",
    "            values = values.union(child_values)\n",
    "        return values\n",
    "        \n",
    "    def areAllChildrenEqual(self):\n",
    "        if len(self.children) == 0:\n",
    "            return True\n",
    "        \n",
    "        values = self.getDecisionValues()\n",
    "        return len(values) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función SplitData recibe como entrada un archivo csv que contiene la informacion del dataset y se encarga de separarla y convertirla en un dataframe lo que la hace mas manejable.\n",
    "* Input: RawData (Data cruda)\n",
    "* Output: data convertida en un dataframe, X siendo una matriz que contiene todos los atributos del dataset y Y siendo un vector columna con el atributo a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and split data into training and test sets\n",
    "def SplitData(Raw_Data):\n",
    "    data = pd.read_csv(Raw_Data,sep = ',')\n",
    "    [n,m] = data.shape\n",
    "    headers = list(data.columns.values)\n",
    "    X = data.iloc[:,0:m-1]\n",
    "    y = data.iloc[:,m-1]\n",
    "    return data, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función Entropy calcula la entropia de la data ingresada mediante la formula: \n",
    "$$ Entropy= -\\sum_j p_j*log_2(p_j) $$\n",
    "Where $p_j$ is the number of ocurrences by events divide by the total number of elements in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(data):\n",
    "    Size_data = len(data)\n",
    "    if Size_data == 0:\n",
    "        return 0\n",
    "    num_classes = [0 for i in data.iloc[:,-1].dropna().value_counts()]\n",
    "    num_classes = data.iloc[:,-1].dropna().value_counts().tolist()\n",
    "    num_classes = [x/Size_data for x in num_classes]\n",
    "    ent = 0\n",
    "    for num in num_classes:\n",
    "        ent += num*math.log(num,2)\n",
    "    return ent*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GainRatio DEBE aceptar valores numericos o NO numericos, Actualmente solo sirve para NO numericos\n",
    "\n",
    "La función Gain_Ratio recibe como entrada los data a los cuales se le va a calcular la proporción de ganancia y los headers que son los nombres de cada atributo. \n",
    "\n",
    "Para calcular las proporciones de ganancia usamos las formulas:\n",
    "\n",
    "Para la ganancia\n",
    "\n",
    "$$ ganacia = \\text{entropia original G} - \\text{ entropia despues de separación por atributo A} $$\n",
    "\n",
    "La formula de proporción de ganancia es:\n",
    "\n",
    "$$\\text{Gain Ratio} = \\frac{ganancia(G,A)}{SplitInfo(G,A)}$$\n",
    "\n",
    "Donde $SplitInfo(G,A) viene de$\n",
    "\n",
    "$$SplitInfo(G,A) = - \\sum^J_{j=1}\\frac{|G_j|}{|G|}log_2\\frac{|G_j|}{|G|} $$\n",
    "\n",
    "Donde $G_j$ es el numero de valores por atributo\n",
    "\n",
    "\n",
    "Los datos pueden ser tanto nomiales como continuos. \n",
    "- Si los datos son nominales:\n",
    "    - Se divide la data en atributos y por cada atributo se sacan sus valores, a estos valores se les calcula su entropia y se decide cual tiene una mayor proporción de ganancia.\n",
    "- Si los datos son continuos\n",
    "    - Algo\n",
    "\n",
    "La función retorna un vector con la proporción de ganancia por atributo, junto con sus valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gain_Ratio(data,headers):\n",
    "    List_entropy = []\n",
    "    List_Sum= []\n",
    "    List_split = []\n",
    "    List_values_Per_Attribute = [] \n",
    "    Global_Entropy = Entropy(data)\n",
    "    for attribute in headers[0:len(headers)-1]:\n",
    "        if (np.issubdtype(data[attribute].dtype, np.number) == False):\n",
    "            entropy = []\n",
    "            values = []\n",
    "            Split = 0\n",
    "            for value in data[attribute].value_counts().index:\n",
    "                # Gain Calculation\n",
    "                values.append(value)\n",
    "                Neg_branch = data.loc[(data[attribute] == value) & (data[headers[len(headers)-1]] == 'No')]\n",
    "                Pos_branch  = data.loc[(data[attribute] == value) & (data[headers[len(headers)-1]] == 'Yes')]\n",
    "                Total_branch = [Neg_branch,Pos_branch]\n",
    "                Total_branch = pd.concat(Total_branch)\n",
    "                probability_num = (len(Total_branch)/len(data))\n",
    "                entropy.append(probability_num*Entropy(Total_branch))\n",
    "                Split += probability_num*math.log(probability_num,2)\n",
    "            Split = Split*-1\n",
    "            List_values_Per_Attribute.append(list(values))\n",
    "            List_split.append(Split)\n",
    "            Sum_per_branch = sum(entropy)\n",
    "            List_entropy.append(list(entropy))\n",
    "            List_Sum.append(Sum_per_branch)\n",
    "        else:\n",
    "            pass\n",
    "            #print(data.sort_values(by = [attribute]))\n",
    "    Gain = np.subtract(Global_Entropy,List_Sum)\n",
    "    GainRatio = np.divide(Gain,List_split)\n",
    "    return GainRatio, List_values_Per_Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función SplitAttributes recibe como entrada la data que se dividira junto con los headers de esta, este algoritmo funciona de forma recursiva. Primero se llamara la función Gain_Ratio la cual calculara las proporciones de ganancia, despues se escogere el atributo con la mayor proporción de ganancia y se escogeran sus valores. Despues estos seran pasados a la función GetSubs la cual se encargara de sacaran **los subconjuntos de acuerdo a los valores del atributo que tuvo la mayor proporción de ganancia**, y con estos se volvera a llamar a la función SplitAttributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitAttributes(RemainingData, headers, parent, leading_value):\n",
    "    headers = list(RemainingData.columns.values)\n",
    "    split_values = []\n",
    "    if len(headers) == 1:\n",
    "        yes = len(RemainingData[RemainingData[headers[0]] == \"Yes\"])\n",
    "        no = len(RemainingData[RemainingData[headers[0]] == \"No\"])\n",
    "        value = None\n",
    "        if yes > no:\n",
    "            value = \"Yes\"\n",
    "        else:\n",
    "            value = \"No\"\n",
    "        node = Node(decision_value=value, entropy_value=0, attribute_name=\"Final Decision\", attribute_value=leading_value, parent=parent, is_final_decision=True)\n",
    "        parent.addChild(node)\n",
    "        return None\n",
    "    else:\n",
    "        #print(\"Current headers \" + str(headers))\n",
    "        GainRatio, values = Gain_Ratio(RemainingData,headers)\n",
    "        index = np.argmax(GainRatio)\n",
    "        GainPos = GainRatio[index]\n",
    "        Best_Attribute = headers[index]\n",
    "        Best_Values = values[index]\n",
    "        #print(\"Best attribute \"+ Best_Attribute + \" -->\")\n",
    "        #print(GainPos)\n",
    "        node = Node(entropy_value=GainPos, attribute_name=Best_Attribute, attribute_value=leading_value, parent=parent, is_final_decision=False)\n",
    "        parent.addChild(node)\n",
    "        Subs = GetSubs(RemainingData,Best_Attribute,Best_Values)\n",
    "        #print(\"Creating node for attribute {} ({}) under parent {}. Number of outcomes: {}\".format(Best_Attribute, GainPos, parent.attrib, len(Subs)))\n",
    "        #print(Best_Values)\n",
    "        #RemainingData = RemainingData.drop(columns=[Best_Attribute])\n",
    "        #headers = list(RemainingData.columns.values)\n",
    "        #print(Subs)\n",
    "        return [SplitAttributes(Subs[i][\"data\"], headers, node, Subs[i][\"val\"]) for i in range(len(Subs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función GetSubs recibe como entrada la data actual, el mejor atributo calculado de la función SplitAttribites y los valores asociados a ese atributo, y devuelve una colección de los dataframes asociados a esos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSubs(data,Best_Attribute, Best_Values):\n",
    "    data_temp = data.copy()\n",
    "    dataframe_collection = {} \n",
    "    for i in range(len(Best_Values)):\n",
    "        dataframe_collection[i] = {\"val\": Best_Values[i], \"data\": data_temp[data_temp[Best_Attribute] == Best_Values[i]].drop(columns= [Best_Attribute])}\n",
    "    return dataframe_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temp', 'Outlook', 'Humidity', 'Play Golf']\n"
     ]
    }
   ],
   "source": [
    "data, X, y = SplitData(\"Golf_Other_Way.csv\")\n",
    "data_temp = data.copy()\n",
    "headers = list(data_temp.columns.values)\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintTree(root, level=0):\n",
    "    if root.is_final_decision:\n",
    "        print(\"{} {}: Decision: {}\".format(\"--\" * level, root.attribute_value, root.decision_value))\n",
    "    else:\n",
    "        print(\"{} Node {} ({}) from edge {}. Prunable: {})\".format(\"--\" * level, root.attribute_name, root.entropy_value, root.attribute_value, root.areAllChildrenEqual()))\n",
    "    for child in root.children:\n",
    "        PrintTree(child, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PruneTree(root):\n",
    "    if root.areAllChildrenEqual():\n",
    "        values = list(root.getDecisionValues())\n",
    "        value = values[0]\n",
    "        root.children = []\n",
    "        root.is_final_decision = True\n",
    "        root.decision_value = value\n",
    "        root.value = 0\n",
    "        root.attrib = \"Final Decision\"\n",
    "    \n",
    "    for child in root.children:\n",
    "        PruneTree(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree before pruning\n",
      " Node -Root- (0) from edge None. Prunable: False)\n",
      "-- Node Outlook (0.1181062751466107) from edge 0. Prunable: False)\n",
      "---- Node Humidity (0.04803508424256193) from edge Rainy. Prunable: False)\n",
      "------ Node Temp (0.31127812445913283) from edge Normal. Prunable: False)\n",
      "-------- Hot: Decision: No\n",
      "-------- Cool: Decision: Yes\n",
      "------ Node Temp (1.0) from edge High. Prunable: False)\n",
      "-------- Hot: Decision: Yes\n",
      "-------- Cool: Decision: No\n",
      "---- Node Temp (-0.0) from edge Overcast. Prunable: True)\n",
      "------ Node Humidity (-0.0) from edge Hot. Prunable: True)\n",
      "-------- High: Decision: Yes\n",
      "-------- Normal: Decision: Yes\n",
      "------ Node Humidity (-0.0) from edge Cool. Prunable: True)\n",
      "-------- High: Decision: Yes\n",
      "-------- Normal: Decision: Yes\n",
      "---- Node Temp (1.0) from edge Sunny. Prunable: False)\n",
      "------ Node Humidity (-0.0) from edge Hot. Prunable: True)\n",
      "-------- High: Decision: No\n",
      "-------- Normal: Decision: No\n",
      "------ Node Humidity (-0.0) from edge Cool. Prunable: True)\n",
      "-------- High: Decision: Yes\n",
      "-------- Normal: Decision: Yes\n",
      "\n",
      "Tree after pruning\n",
      " Node -Root- (0) from edge None. Prunable: False)\n",
      "-- Node Outlook (0.1181062751466107) from edge 0. Prunable: False)\n",
      "---- Node Humidity (0.04803508424256193) from edge Rainy. Prunable: False)\n",
      "------ Node Temp (0.31127812445913283) from edge Normal. Prunable: False)\n",
      "-------- Hot: Decision: No\n",
      "-------- Cool: Decision: Yes\n",
      "------ Node Temp (1.0) from edge High. Prunable: False)\n",
      "-------- Hot: Decision: Yes\n",
      "-------- Cool: Decision: No\n",
      "---- Overcast: Decision: Yes\n",
      "---- Node Temp (1.0) from edge Sunny. Prunable: False)\n",
      "------ Hot: Decision: No\n",
      "------ Cool: Decision: Yes\n"
     ]
    }
   ],
   "source": [
    "root = Node(attribute_name='-Root-', entropy_value=0, parent=None, attribute_value=None, is_final_decision=False)\n",
    "Splitter = SplitAttributes(data_temp, headers, root, 0)\n",
    "Splitter\n",
    "\n",
    "print(\"Tree before pruning\")\n",
    "PrintTree(root)\n",
    "\n",
    "# Prune the tree to remove redundant branches\n",
    "PruneTree(root)\n",
    "\n",
    "print()\n",
    "print(\"Tree after pruning\")\n",
    "PrintTree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "[1] https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec08.pdf\n",
    "\n",
    "[2] https://saiconference.com/Downloads/SpecialIssueNo10/Paper_3A_comparative_study_of_decision_tree_ID3_and_C4.5.pdf\n",
    "\n",
    "[3] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5368063"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
